{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pandas as pd\nimport seaborn as sn\nimport matplotlib.pyplot as plt\nimport numpy as np\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom xgboost import XGBClassifier\nfrom lightgbm import LGBMClassifier\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.ensemble import AdaBoostClassifier\nfrom sklearn.ensemble import GradientBoostingClassifier\nfrom sklearn.ensemble import BaggingClassifier\nfrom keras.models import Sequential\nfrom keras.layers import Dense\nimport keras.activations,keras.optimizers,keras.losses","metadata":{"execution":{"iopub.status.busy":"2023-09-21T17:28:44.945665Z","iopub.execute_input":"2023-09-21T17:28:44.946157Z","iopub.status.idle":"2023-09-21T17:28:44.953898Z","shell.execute_reply.started":"2023-09-21T17:28:44.946112Z","shell.execute_reply":"2023-09-21T17:28:44.952778Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data=pd.read_csv(\"/kaggle/input/iot-dataset-for-intrusion-detection-systems-ids/BoTNeTIoT-L01-v2.csv\")\nprint(data.columns)\nprint(data.describe())\nprint(data.isna().sum())\nprint(data.info())\nprint(len(data.columns))\n","metadata":{"execution":{"iopub.status.busy":"2023-09-21T17:28:44.956217Z","iopub.execute_input":"2023-09-21T17:28:44.957075Z","iopub.status.idle":"2023-09-21T17:29:20.76486Z","shell.execute_reply.started":"2023-09-21T17:28:44.957035Z","shell.execute_reply":"2023-09-21T17:29:20.763729Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for i in data.select_dtypes(include='number').columns.values:\n    sn.boxplot(data[i])\n    plt.show()","metadata":{"execution":{"iopub.status.busy":"2023-09-21T17:29:20.767653Z","iopub.execute_input":"2023-09-21T17:29:20.76813Z","iopub.status.idle":"2023-09-21T17:30:03.454359Z","shell.execute_reply.started":"2023-09-21T17:29:20.768088Z","shell.execute_reply":"2023-09-21T17:30:03.453421Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for i in data.select_dtypes(include='object').columns.values:\n    if len(data[i].value_counts()) <=10:\n        val=data[i].value_counts().values\n        index=data[i].value_counts().index\n        plt.pie(val,labels=index,autopct='%1.1f%%')\n        plt.title(f'The PIE Chart information of {i} column')\n        plt.show()","metadata":{"execution":{"iopub.status.busy":"2023-09-21T17:30:03.456301Z","iopub.execute_input":"2023-09-21T17:30:03.456614Z","iopub.status.idle":"2023-09-21T17:30:09.042203Z","shell.execute_reply.started":"2023-09-21T17:30:03.456588Z","shell.execute_reply":"2023-09-21T17:30:09.040725Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for i in data.select_dtypes(include='object').columns.values:\n    print(data[i].value_counts())\n    print(\"--------------------------------\")\n","metadata":{"execution":{"iopub.status.busy":"2023-09-21T17:30:09.044111Z","iopub.execute_input":"2023-09-21T17:30:09.044852Z","iopub.status.idle":"2023-09-21T17:30:10.858573Z","shell.execute_reply.started":"2023-09-21T17:30:09.044792Z","shell.execute_reply":"2023-09-21T17:30:10.857554Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"lab=LabelEncoder()\nfor i in data.select_dtypes(include='object').columns.values:\n    data[i]=lab.fit_transform(data[i])\n","metadata":{"execution":{"iopub.status.busy":"2023-09-21T17:30:10.859907Z","iopub.execute_input":"2023-09-21T17:30:10.860311Z","iopub.status.idle":"2023-09-21T17:30:15.575622Z","shell.execute_reply.started":"2023-09-21T17:30:10.860282Z","shell.execute_reply":"2023-09-21T17:30:15.574563Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"x={}\nX=[]\nfor i in data.columns.values:\n    data['z-scores']=(data[i]-data[i].mean())/(data[i].std())\n    outliers=np.abs(data['z-scores'] > 3).sum()\n    x[i]=outliers\n","metadata":{"execution":{"iopub.status.busy":"2023-09-21T17:30:15.57699Z","iopub.execute_input":"2023-09-21T17:30:15.577318Z","iopub.status.idle":"2023-09-21T17:30:18.707562Z","shell.execute_reply.started":"2023-09-21T17:30:15.577291Z","shell.execute_reply":"2023-09-21T17:30:18.706515Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for keys,values in x.items():\n    if values>0:\n        X.append(keys)\nprint(x)","metadata":{"execution":{"iopub.status.busy":"2023-09-21T17:30:18.708762Z","iopub.execute_input":"2023-09-21T17:30:18.709097Z","iopub.status.idle":"2023-09-21T17:30:18.715343Z","shell.execute_reply.started":"2023-09-21T17:30:18.70907Z","shell.execute_reply":"2023-09-21T17:30:18.714257Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"x=[]\n\nthresh=2\nfor i in data[X].columns.values:\n    upper=data[i].mean()+thresh*data[i].std()\n    lower=data[i].mean()-thresh*data[i].std()\n    data=data[(data[i]>lower)&(data[i]<upper)]\n\nprint(len(data))","metadata":{"execution":{"iopub.status.busy":"2023-09-21T17:30:18.718107Z","iopub.execute_input":"2023-09-21T17:30:18.718407Z","iopub.status.idle":"2023-09-21T17:30:34.562029Z","shell.execute_reply.started":"2023-09-21T17:30:18.718382Z","shell.execute_reply":"2023-09-21T17:30:34.561045Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"corr=data.corr()['Attack']\ncorr=corr.drop(['Attack','z-scores','label'])\nfor i in corr.index:\n    print(i)\n    if corr[i] > 0.25:\n        x.append(i)","metadata":{"execution":{"iopub.status.busy":"2023-09-21T17:30:34.563465Z","iopub.execute_input":"2023-09-21T17:30:34.563775Z","iopub.status.idle":"2023-09-21T17:30:45.556399Z","shell.execute_reply.started":"2023-09-21T17:30:34.563748Z","shell.execute_reply":"2023-09-21T17:30:45.555218Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X=data[x]\ndata['Attack']=lab.fit_transform(data['Attack'])\nY=data['Attack']\nx_train,x_test,y_train,y_test=train_test_split(X,Y)\n\nlr = LogisticRegression(max_iter=500)\nlr.fit(x_train, y_train)\nprint('The logistic regression: ', lr.score(x_test, y_test))\n\nlgb = LGBMClassifier() \nlgb.fit(x_train, y_train)\nprint('The LGB', lgb.score(x_test, y_test))\n\ntree = DecisionTreeClassifier(criterion='entropy', max_depth=5)\ntree.fit(x_train, y_train)\nprint('Dtree ', tree.score(x_test,y_test))","metadata":{"execution":{"iopub.status.busy":"2023-09-21T17:30:45.557738Z","iopub.execute_input":"2023-09-21T17:30:45.558546Z","iopub.status.idle":"2023-09-21T17:31:28.510952Z","shell.execute_reply.started":"2023-09-21T17:30:45.558513Z","shell.execute_reply":"2023-09-21T17:31:28.509753Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"x=data[x]\nprint(len(x))\ny=pd.get_dummies(data['Attack'])\nx_trin,x_tst,y_trin,y_tst=train_test_split(x,y)\nmodels=Sequential()\nmodels.add(Dense(units=x.shape[1],input_dim=x.shape[1],activation=keras.activations.relu))\nmodels.add(Dense(units=x.shape[1],activation=keras.activations.softmax))\nmodels.add(Dense(units=x.shape[1],activation=keras.activations.softmax))\nmodels.add(Dense(units=x.shape[1],activation=keras.activations.softmax))\nmodels.add(Dense(units=y.shape[1],activation=keras.activations.softmax))\nmodels.compile(optimizer='adam',loss=keras.losses.categorical_crossentropy,metrics='accuracy')\nhist=models.fit(x_trin,y_trin,batch_size=500,epochs=50)\nplt.plot(hist.history['accuracy'], label='training accuracy', marker='o', color='red')\nplt.plot(hist.history['loss'], label='loss', marker='o', color='darkblue')\nplt.title('Training Vs  Validation accuracy with adam optimizer')\nplt.legend()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-09-21T17:31:28.512133Z","iopub.execute_input":"2023-09-21T17:31:28.512452Z","iopub.status.idle":"2023-09-21T17:42:19.925362Z","shell.execute_reply.started":"2023-09-21T17:31:28.512424Z","shell.execute_reply":"2023-09-21T17:42:19.924513Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np\nimport tensorflow as tf\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Conv1D, MaxPooling1D, Flatten, LSTM, GRU, Dense\nfrom sklearn.metrics import accuracy_score, f1_score\nfrom sklearn.ensemble import VotingClassifier\nfrom sklearn.model_selection import train_test_split\n\n# Define your CNN model\ndef create_cnn_model(input_shape, num_classes):\n    model = Sequential()\n    model.add(Conv1D(filters=64, kernel_size=3, activation='relu', input_shape=input_shape))\n    model.add(MaxPooling1D(pool_size=2))\n    model.add(Flatten())\n    model.add(Dense(128, activation='relu'))\n    model.add(Dense(num_classes, activation='softmax'))\n    return model\n\n# Define your LSTM model\ndef create_lstm_model(input_shape, num_classes):\n    model = Sequential()\n    model.add(LSTM(64, input_shape=input_shape))\n    model.add(Dense(num_classes, activation='softmax'))\n    return model\n\n# Define your GRU model\ndef create_gru_model(input_shape, num_classes):\n    model = Sequential()\n    model.add(GRU(64, input_shape=input_shape))\n    model.add(Dense(num_classes, activation='softmax'))\n    return model\n\n# Load and preprocess  IoT intrusion dataset\n# Replace this with your dataset loading and preprocessing code\nX, y = load_and_preprocess_data()\n\n# Split the data into training and testing sets\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\n# Create CNN, LSTM, and GRU models\ninput_shape = X_train.shape[1:]\nnum_classes = len(np.unique(y_train))\n\ncnn_model = create_cnn_model(input_shape, num_classes)\nlstm_model = create_lstm_model(input_shape, num_classes)\ngru_model = create_gru_model(input_shape, num_classes)\n\n# Compile models\ncnn_model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\nlstm_model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\ngru_model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n\n# Train models\ncnn_model.fit(X_train, y_train, epochs=10, batch_size=64)\nlstm_model.fit(X_train, y_train, epochs=10, batch_size=64)\ngru_model.fit(X_train, y_train, epochs=10, batch_size=64)\n\n# Make predictions\ncnn_pred = cnn_model.predict(X_test)\nlstm_pred = lstm_model.predict(X_test)\ngru_pred = gru_model.predict(X_test)\n\n# Create an ensemble model with both hard and soft voting\nensemble_hard = VotingClassifier(estimators=[\n    ('cnn', cnn_model),\n    ('lstm', lstm_model),\n    ('gru', gru_model)\n], voting='hard')\n\nensemble_soft = VotingClassifier(estimators=[\n    ('cnn', cnn_model),\n    ('lstm', lstm_model),\n    ('gru', gru_model)\n], voting='soft')\n\nensemble_hard.fit(X_train, y_train)\nensemble_soft.fit(X_train, y_train)\n\nensemble_hard_pred = ensemble_hard.predict(X_test)\nensemble_soft_pred = ensemble_soft.predict(X_test)\n\n# Evaluate the models\ncnn_accuracy = accuracy_score(np.argmax(y_test, axis=1), np.argmax(cnn_pred, axis=1))\nlstm_accuracy = accuracy_score(np.argmax(y_test, axis=1), np.argmax(lstm_pred, axis=1))\ngru_accuracy = accuracy_score(np.argmax(y_test, axis=1), np.argmax(gru_pred, axis_1))\nensemble_hard_accuracy = accuracy_score(y_test, ensemble_hard_pred)\nensemble_soft_accuracy = accuracy_score(y_test, ensemble_soft_pred)\n\ncnn_f1 = f1_score(np.argmax(y_test, axis=1), np.argmax(cnn_pred, axis=1), average='weighted')\nlstm_f1 = f1_score(np.argmax(y_test, axis=1), np.argmax(lstm_pred, axis=1), average='weighted')\ngru_f1 = f1_score(np.argmax(y_test, axis=1), np.argmax(gru_pred, axis=1), average='weighted')\nensemble_hard_f1 = f1_score(y_test, ensemble_hard_pred, average='weighted')\nensemble_soft_f1 = f1_score(y_test, ensemble_soft_pred, average='weighted')\n\n# Print the results\nprint(f\"CNN Accuracy: {cnn_accuracy}\")\nprint(f\"LSTM Accuracy: {lstm_accuracy}\")\nprint(f\"GRU Accuracy: {gru_accuracy}\")\nprint(f\"Ensemble (Hard Voting) Accuracy: {ensemble_hard_accuracy}\")\nprint(f\"Ensemble (Soft Voting) Accuracy: {ensemble_soft_accuracy}\")\n\nprint(f\"CNN F1-Score: {cnn_f1}\")\nprint(f\"LSTM F1-Score: {lstm_f1}\")\nprint(f\"GRU F1-Score: {gru_f1}\")\nprint(f\"Ensemble (Hard Voting) F1-Score: {ensemble_hard_f1}\")\nprint(f\"Ensemble (Soft Voting) F1-Score: {ensemble_soft_f1}\")\n","metadata":{},"execution_count":null,"outputs":[]}]}